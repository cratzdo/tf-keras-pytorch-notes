{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Most of the codes are manually copied (typed) from Aurélien Géron's book, his notebook is [here](https://github.com/ageron/handson-ml). I used this notebook to get myself familiar with the details of RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = ('svg', 'retina')\n",
    "plt.style.use('my_custom_style')\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.edgecolor'] = 'white'\n",
    "mpl.rcParams['figure.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "\n",
    "training = tf.placeholder(tf.bool, shape=(), name=\"is_training\")\n",
    "\n",
    "\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\")\n",
    "bn1 = tf.layers.batch_normalization(hidden1, training=training, momentum=0.9)\n",
    "bn1_act = tf.nn.elu(bn1)\n",
    "\n",
    "hidden2 = tf.layers.dense(bn1_act, n_hidden2, name=\"hidden2\")\n",
    "bn1 = tf.layers.batch_normalization(hidden2, training=training, momentum=0.9)\n",
    "bn2_act = tf.nn.elu(bn2)\n",
    "\n",
    "logits_before_bn = tf.layers.dense(bn2_act, n_outputs, name=\"outputs\")\n",
    "logits = tf.layers.batch_normalization(logits_before_bn, training=training,\n",
    "                                       momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Vanilla RNN\n",
    "\n",
    "Below is a vanilla recurrent neural network (RNN) to illusrate the concept of this type neural nets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- For an RNN with a single recurrent neuron, the output can be written as\n",
    "$y_{(t)}=\\phi(x_{(t)}^T\\cdot w_x + y_{(t-1)} w_y + b)$. Note that the output of the previous state is now a feature of the current state.\n",
    "\n",
    "- For a mini-batch of the shape $m\\times n_{neurons}$, the prediction of the current state can be written as\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "Y_{(t)} &= \\phi(X_{(t)}\\cdot W_x + Y_{(t-1)}\\cdot W_y + b) \\\\\n",
    "    &= \\phi([X_{(t)} Y_{(t-1)}]\\cdot W + b)\n",
    "\\end{align*}    \n",
    "$$\n",
    "\n",
    "where $\\mathbf{W} = [\\mathbf{W}_x \\mathbf{W}_y]^T$.\n",
    "\n",
    "- $\\mathbf{W}_x$ is an $n_{inputs}\\times n_{neurons}$ matrix\n",
    "- $W_y$ is an $n_{neurons}\\times n_{neurons}$ matrix\n",
    "- $X_{(t)}$ is an $m\\times n_{inputs}$ matrix\n",
    "- $Y_{(t)}$ is an $m\\times n_{neurons}$ matrix\n",
    "- $b$ is a vector of size $n_{neurons}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "## pseudo RNN for illustration\n",
    "class RNN:\n",
    "    #...\n",
    "    def step(self, x):\n",
    "        # update the hidden state\n",
    "        self.h = np.tanh(np.dot(self.W_hh, self.h) + np.dot(self.W_xh, x))\n",
    "        # compute the output vector\n",
    "        y = np.dot(self.W_hy, self.h)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Manual RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "\n",
    "X0 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "X1 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "\n",
    "Wx = tf.Variable(tf.random_normal(shape=[n_inputs, n_neurons]))\n",
    "Wy = tf.Variable(tf.random_normal(shape=[n_neurons, n_neurons]))\n",
    "b = tf.Variable(tf.zeros([1, n_neurons]))\n",
    "\n",
    "Y0 = tf.tanh(tf.matmul(X0, Wx) + b)\n",
    "Y1 = tf.tanh(tf.matmul(Y0, Wy) + tf.matmul(X1, Wx) + b)\n",
    "\n",
    "init = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output at t=0\n",
      "\n",
      " [[-0.0664006   0.9625767   0.68105793  0.7091854  -0.898216  ]\n",
      " [ 0.9977755  -0.719789   -0.9965761   0.9673924  -0.9998972 ]\n",
      " [ 0.99999774 -0.99898803 -0.9999989   0.9967762  -0.9999999 ]\n",
      " [ 1.         -1.         -1.         -0.99818915  0.9995087 ]]\n",
      "================================================================================\n",
      "Output at t=1\n",
      "\n",
      " [[ 1.         -1.         -1.          0.4020025  -0.9999998 ]\n",
      " [-0.12210419  0.62805265  0.9671843  -0.9937122  -0.2583937 ]\n",
      " [ 0.9999983  -0.9999994  -0.9999975  -0.85943305 -0.9999881 ]\n",
      " [ 0.99928284 -0.99999815 -0.9999058   0.9857963  -0.92205757]]\n"
     ]
    }
   ],
   "source": [
    "# a mini-batch with four instances\n",
    "X0_batch = np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 0, 1]]) # t=0\n",
    "X1_batch = np.array([[9, 8, 7], [0, 0, 0], [6, 5, 4], [3, 2, 1]]) # t=1\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    Y0_val, Y1_val = sess.run([Y0, Y1], feed_dict={X0: X0_batch, X1: X1_batch})\n",
    "\n",
    "print('Output at t=0\\n\\n', Y0_val)\n",
    "print(\"=\"*80)\n",
    "print('Output at t=1\\n\\n', Y1_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Since our naive RNN has only five neurons, and the mini-batch is of shape $4\\times 3$, and thus the  shape of the output Y1_val should be $(4\\times 3) \\times (3\\times 5) = (4\\times 5)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Static Unrolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "\n",
    "X0_batch = np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 0, 1]]) # t=0\n",
    "X1_batch = np.array([[9, 8, 7], [0, 0, 0], [6, 5, 4], [3, 2, 1]]) # t=1\n",
    "\n",
    "X0 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "X1 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "output_seqs, states = tf.contrib.rnn.static_rnn(basic_cell, [X0, X1],\n",
    "                                                dtype=tf.float32)\n",
    "Y0, Y1 = output_seqs\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    Y0_val, Y1_val, states_ = sess.run([Y0, Y1, states], feed_dict={X0: X0_batch, X1: X1_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output at t=0\n",
      "\n",
      " [[ 0.30741334 -0.32884315 -0.6542847  -0.9385059   0.52089024]\n",
      " [ 0.99122757 -0.9542541  -0.7518079  -0.9995208   0.9820235 ]\n",
      " [ 0.9999268  -0.99783254 -0.8247353  -0.9999963   0.99947774]\n",
      " [ 0.996771   -0.68750614  0.8419969   0.9303911   0.8120684 ]]\n",
      "================================================================================\n",
      "Output at t=1\n",
      "\n",
      " [[ 0.99998885 -0.99976057 -0.0667929  -0.9999803   0.99982214]\n",
      " [-0.6524943  -0.51520866 -0.37968948 -0.5922594  -0.08968379]\n",
      " [ 0.99862397 -0.99715203 -0.03308626 -0.9991566   0.9932902 ]\n",
      " [ 0.99681675 -0.9598194   0.39660627 -0.8307606   0.79671973]]\n",
      "================================================================================\n",
      "Final states are\n",
      " [[ 0.99998885 -0.99976057 -0.0667929  -0.9999803   0.99982214]\n",
      " [-0.6524943  -0.51520866 -0.37968948 -0.5922594  -0.08968379]\n",
      " [ 0.99862397 -0.99715203 -0.03308626 -0.9991566   0.9932902 ]\n",
      " [ 0.99681675 -0.9598194   0.39660627 -0.8307606   0.79671973]]\n"
     ]
    }
   ],
   "source": [
    "print('Output at t=0\\n\\n', Y0_val)\n",
    "print(\"=\"*80)\n",
    "print('Output at t=1\\n\\n', Y1_val)\n",
    "print(\"=\"*80)\n",
    "print(\"Final states are\\n\", states_) # this is simply the last output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Handle long time-steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_steps = 2\n",
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "# swap the positions of time-steps and features in X\n",
    "X_seqs = tf.unstack(tf.transpose(X, perm=[1, 0, 2])) \n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "output_seqs, states = tf.contrib.rnn.static_rnn(basic_cell,\n",
    "                                                X_seqs, dtype=tf.float32)\n",
    "# change the shape of output back to that of X\n",
    "outputs = tf.transpose(tf.stack(output_seqs), perm=[1, 0, 2])\n",
    "\n",
    "X_batchs = np.array([\n",
    "    [[0, 1, 2], [9, 8, 7]],\n",
    "    [[3, 4, 5], [0, 0, 0]],\n",
    "    [[6, 7, 8], [6, 5, 4]],\n",
    "    [[9, 0, 1], [3, 2, 1]],\n",
    "])\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val = outputs.eval(feed_dict={X: X_batchs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.45652324 -0.68064123  0.40938237  0.63104504 -0.45732826]\n",
      "  [-0.9428799  -0.9998869   0.94055814  0.9999985  -0.9999997 ]]\n",
      "\n",
      " [[-0.8001535  -0.9921827   0.7817797   0.9971032  -0.9964609 ]\n",
      "  [-0.637116    0.11300927  0.5798437   0.4310559  -0.6371699 ]]\n",
      "\n",
      " [[-0.93605185 -0.9998379   0.9308867   0.9999815  -0.99998295]\n",
      "  [-0.9165386  -0.9945604   0.896054    0.99987197 -0.9999751 ]]\n",
      "\n",
      " [[ 0.9927369  -0.9981933  -0.55543643  0.9989031  -0.9953323 ]\n",
      "  [-0.02746338 -0.73191994  0.7827872   0.9525682  -0.9781773 ]]]\n"
     ]
    }
   ],
   "source": [
    "print(outputs_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The static rolling method is still problematic, as it will need to creat n_steps copies of the basic RNN cell. As the n_steps increases, we will face the out-of-memory problem, especially when using GPU. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Use dynamic unrolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 3\n",
    "n_steps = 2\n",
    "n_neurons = 5\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)\n",
    "\n",
    "X_batchs = np.array([\n",
    "    [[0, 1, 2], [9, 8, 7]],\n",
    "    [[3, 4, 5], [0, 0, 0]],\n",
    "    [[6, 7, 8], [6, 5, 4]],\n",
    "    [[9, 0, 1], [3, 2, 1]],\n",
    "])\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val = outputs.eval(feed_dict={X: X_batchs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used dynamic_rnn\n",
      "\n",
      " [[[-0.85115266  0.87358344  0.5802911   0.8954789  -0.0557505 ]\n",
      "  [-0.999996    0.99999577  0.9981815   1.          0.37679607]]\n",
      "\n",
      " [[-0.9983293   0.9992038   0.98071456  0.999985    0.25192663]\n",
      "  [-0.7081804  -0.0772338  -0.85227895  0.5845349  -0.78780943]]\n",
      "\n",
      " [[-0.9999827   0.99999535  0.9992863   1.          0.5159072 ]\n",
      "  [-0.9993956   0.9984095   0.83422637  0.99999976 -0.47325212]]\n",
      "\n",
      " [[ 0.87888587  0.07356028  0.97216916  0.9998546  -0.7351168 ]\n",
      "  [-0.9134514   0.3600957   0.7624866   0.99817705  0.80142   ]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Used dynamic_rnn\\n\\n\", outputs_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Setting the sequence length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "`help(tf.nn.dynamic_rnn)`\n",
    "\n",
    "```python\n",
    "dynamic_rnn(cell, inputs, sequence_length=None, initial_state=None, dtype=None, parallel_iterations=None, swap_memory=False, time_major=False, scope=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_steps = 2\n",
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "seq_length = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32,\n",
    "                                    sequence_length=seq_length)\n",
    "\n",
    "\n",
    "X_batch = np.array([\n",
    "    [[0, 1, 2], [9, 8, 7]],\n",
    "    [[3, 4, 5], [0, 0, 0]], # (padded with zero vector)\n",
    "    [[6, 7, 8], [6, 5, 4]],\n",
    "    [[9, 0, 1], [3, 2, 1]],\n",
    "])\n",
    "\n",
    "seq_length_batch = np.array([2, 1, 2, 2])\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    outputs_val, states_val = sess.run([outputs, states],\n",
    "                                       feed_dict={X: X_batch,\n",
    "                                                  seq_length: seq_length_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with sequence length manually setted\n",
      "\n",
      " [[[-0.9123188   0.16516446  0.5548655  -0.39159346  0.20846416]\n",
      "  [-1.          0.956726    0.99831694  0.99970174  0.96518576]]\n",
      "\n",
      " [[-0.9998612   0.6702289   0.9723653   0.6631046   0.74457586]\n",
      "  [ 0.          0.          0.          0.          0.        ]]\n",
      "\n",
      " [[-0.99999976  0.8967997   0.9986295   0.9647514   0.93662   ]\n",
      "  [-0.9999526   0.9681953   0.96002865  0.98706263  0.85459226]]\n",
      "\n",
      " [[-0.96435434  0.99501586 -0.36150697  0.9983378   0.999497  ]\n",
      "  [-0.9613586   0.9568762   0.7132288   0.97729224 -0.0958299 ]]]\n",
      "\n",
      " ============================================================\n",
      "[[-1.          0.956726    0.99831694  0.99970174  0.96518576]\n",
      " [-0.9998612   0.6702289   0.9723653   0.6631046   0.74457586]\n",
      " [-0.9999526   0.9681953   0.96002865  0.98706263  0.85459226]\n",
      " [-0.9613586   0.9568762   0.7132288   0.97729224 -0.0958299 ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"with sequence length manually setted\\n\\n\", outputs_val)\n",
    "print(\"\\n\", \"=\"*60)\n",
    "print(states_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Training a sequence classifier\n",
    "\n",
    "Training a RNN classifier for MNIST images. Treat an image as a sequence! A MNIST image is of the shape $28\\times 28$, we can treat it as a sequence of 28 rows of 28 pixels each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_steps = 28\n",
    "n_inputs = 28\n",
    "n_neurons = 100\n",
    "n_outputs = 10 # number of digits (0-9)\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)\n",
    "\n",
    "logits_ = tf.layers.dense(states, n_outputs)\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits_)\n",
    "\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "correct = tf.nn.in_top_k(logits_, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\")\n",
    "X_test = mnist.test.images.reshape((-1, n_steps, n_inputs))\n",
    "y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=19, Training acc=0.9600, Testing acc=0.9688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=18, Training acc=0.9800, Testing acc=0.9682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=17, Training acc=0.9800, Testing acc=0.9708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=16, Training acc=0.9667, Testing acc=0.9725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=15, Training acc=0.9867, Testing acc=0.9718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=14, Training acc=0.9867, Testing acc=0.9690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=13, Training acc=0.9800, Testing acc=0.9666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=12, Training acc=0.9533, Testing acc=0.9720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=11, Training acc=0.9867, Testing acc=0.9726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=10, Training acc=1.0000, Testing acc=0.9711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=9, Training acc=0.9667, Testing acc=0.9688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=8, Training acc=0.9933, Testing acc=0.9621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=7, Training acc=0.9867, Testing acc=0.9665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=6, Training acc=0.9800, Testing acc=0.9638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=5, Training acc=0.9733, Testing acc=0.9512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=4, Training acc=0.9867, Testing acc=0.9526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=3, Training acc=0.9600, Testing acc=0.9381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=2, Training acc=0.9067, Testing acc=0.9399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=1, Training acc=0.9600, Testing acc=0.9340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, Training acc=0.9000, Testing acc=0.9170\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 150\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            X_batch = X_batch.reshape((-1, n_steps, n_inputs))\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "        print(f\"epoch={epoch+1}, Training acc={acc_train:.4f}, Testing acc={acc_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "This is just a toy example with very thrift learning parameters, because my poor Macbook Pro cannot handle more trianing epochs and a smaller learning rate. Otherwise, it will take forever to finish the training.\n",
    "\n",
    "Anyhow, we achieved a test accuracy about 97.3% at the 11th epochs. Note that the RNN starts to overfit at the 12th epoch, given the relatively large learning rate (lr=1e-3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# RNN for Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "t_min, t_max = 0, 30\n",
    "resolution = 0.1\n",
    "\n",
    "def time_series(t):\n",
    "    return t * np.sin(t) / 3 + 2 * np.sin(t*5)\n",
    "\n",
    "#  Instead of fetching a mini-batch from an existing data set\n",
    "# this helper function creates a mini-batch each\n",
    "def next_batch(batch_size, n_steps):\n",
    "    t0 = np.random.randn(batch_size, 1) * (t_max - t_min - n_steps * resolution)\n",
    "    Ts = t0 + np.arange(0., n_steps+1) * resolution\n",
    "    ys = time_series(Ts)\n",
    "    return ys[:, :-1].reshape(-1, n_steps, 1), ys[:, 1:].reshape(-1, n_steps, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = np.linspace(t_min, t_max, int((t_max - t_min) / resolution))\n",
    "\n",
    "n_steps = 20\n",
    "t_instance = np.linspace(12.2, 12.2 + resolution * (n_steps + 1), n_steps + 1)\n",
    "\n",
    "colors = ['#e66101','#fdb863','#b2abd2','#5e3c99']\n",
    "\n",
    "plt.figure(figsize=(6,10))\n",
    "plt.subplot(211)\n",
    "plt.title(\"A time series (generated)\", fontsize=14)\n",
    "plt.plot(t, time_series(t), label=r\"$t . \\sin(t) / 3 + 2 . \\sin(5t)$\", c=colors[0])\n",
    "plt.plot(t_instance[:-1], time_series(t_instance[:-1]),\n",
    "         \"-\", c=colors[3],\n",
    "         linewidth=2, label=\"A training instance\")\n",
    "plt.legend(loc=\"lower left\", fontsize=14)\n",
    "plt.axis([0, 30, -17, 13])\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Value\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"A training instance\", fontsize=14)\n",
    "plt.plot(t_instance[:-1], time_series(t_instance[:-1]),\n",
    "         \"o\", c=colors[3], markersize=10, label=\"instance\")\n",
    "plt.plot(t_instance[1:], time_series(t_instance[1:]),\n",
    "         \"^\", c=colors[0], markersize=6, label=\"target\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel(\"Time\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_steps = 20\n",
    "n_inputs = 1\n",
    "n_neurons = 100\n",
    "n_outputs = 1\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.float32, [None, n_steps, n_outputs])\n",
    "\n",
    "# use an OutputProjectionWrapper to automatically stack the output\n",
    "# otherwise we need to do it ourselves (use `reshape`)\n",
    "cell = tf.contrib.rnn.OutputProjectionWrapper(\n",
    "    tf.contrib.rnn.BasicRNNCell(num_units=n_neurons, activation=tf.nn.relu),\n",
    "    output_size=n_outputs)\n",
    "\n",
    "outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(outputs - y)) # MSE\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400\tMSE: 0.0834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300\tMSE: 0.0713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\tMSE: 0.0554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100\tMSE: 0.0605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\tMSE: 0.0640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900\tMSE: 0.0644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\tMSE: 0.0861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700\tMSE: 0.0645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\tMSE: 0.0611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\tMSE: 0.0771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\tMSE: 0.0950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\tMSE: 0.1081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\tMSE: 0.2971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\tMSE: 1.6234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tMSE: 31.5879\n"
     ]
    }
   ],
   "source": [
    "n_iter = 1500\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for iter in range(n_iter):\n",
    "        X_batch, y_batch = next_batch(batch_size, n_steps)\n",
    "        sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if iter % 100 == 0:\n",
    "            mse = loss.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "            print(f\"{iter}\\tMSE: {mse:.4f}\")\n",
    "    saver.save(sess, \"./my_time_series_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_time_series_model\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_time_series_model\")\n",
    "\n",
    "    X_new = time_series(np.array(t_instance[:-1].reshape(-1, n_steps, n_inputs)))\n",
    "    y_pred1 = sess.run(outputs, feed_dict={X: X_new})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-3.5123656 ],\n        [-2.4479904 ],\n        [-1.0369046 ],\n        [ 0.75989497],\n        [ 2.1721063 ],\n        [ 3.0693047 ],\n        [ 3.5415273 ],\n        [ 3.3060033 ],\n        [ 2.826444  ],\n        [ 2.280538  ],\n        [ 1.6957043 ],\n        [ 1.4992216 ],\n        [ 1.8971107 ],\n        [ 2.7551672 ],\n        [ 3.9230437 ],\n        [ 5.108908  ],\n        [ 6.131944  ],\n        [ 6.70724   ],\n        [ 6.6501303 ],\n        [ 6.068209  ]]], dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 576x411.429 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(figsize=(8, 8/1.4))\n",
    "plt.title(\"Testing the model\", fontsize=14)\n",
    "plt.plot(t_instance[:-1], time_series(t_instance[:-1]),\n",
    "         \"o\", c=colors[0], markersize=8, label=\"instance\")\n",
    "plt.plot(t_instance[1:], time_series(t_instance[1:]),\n",
    "         \"^\", c=colors[3], markersize=6, label=\"target\")\n",
    "plt.plot(t_instance[1:], y_pred1[0,:,0],\n",
    "         \".\", c=colors[2], markersize=8, label=\"prediction\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel(\"Time\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Multi-layer RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 1\n",
    "n_steps = 5\n",
    "n_outputs = 1\n",
    "n_neurons = 100\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.placeholder(tf.float32, [None, n_steps, n_outputs])\n",
    "\n",
    "n_neurons = 100\n",
    "n_layers = 3\n",
    "\n",
    "layers = [tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "          for layer in range(n_layers)]\n",
    "multi_layer_cell = tf.contrib.rnn.MultiRNNCell(layers)\n",
    "rnn_outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32)\n",
    "rnn_outputs_stack = tf.reshape(rnn_outputs, [-1, n_neurons])\n",
    "outputs_stack = tf.layers.dense(rnn_outputs_stack, n_outputs)\n",
    "outputs = tf.reshape(outputs_stack, [-1, n_steps, n_outputs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(outputs - y)) # MSE\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "training_op = optimizer.minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#  Instead of fetching a mini-batch from an existing data set\n",
    "# this helper function creates a mini-batch each\n",
    "def next_batch(batch_size, n_steps):\n",
    "    t0 = np.random.randn(batch_size, 1) * (t_max - t_min - n_steps * resolution)\n",
    "    Ts = t0 + np.arange(0., n_steps+1) * resolution\n",
    "    ys = time_series(Ts)\n",
    "    return ys[:, :-1].reshape(-1, n_steps, 1), ys[:, 1:].reshape(-1, n_steps, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400\tMSE: 0.0831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300\tMSE: 0.0697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\tMSE: 0.0678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100\tMSE: 0.0765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\tMSE: 0.0617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900\tMSE: 0.0662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\tMSE: 0.0759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700\tMSE: 0.0758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\tMSE: 0.0890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\tMSE: 0.0967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\tMSE: 0.0890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\tMSE: 0.0982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\tMSE: 0.4850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\tMSE: 1.4701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tMSE: 32.8862\n"
     ]
    }
   ],
   "source": [
    "n_iter = 1500\n",
    "batch_size = 50\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for iter in range(n_iter):\n",
    "        X_batch, y_batch = next_batch(batch_size, n_steps)\n",
    "        sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if iter % 100 == 0:\n",
    "            mse = loss.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "            print(f\"{iter}\\tMSE: {mse:.4f}\")\n",
    "            \n",
    "    X_new = time_series(np.array(t_instance[:-1].reshape(-1, n_steps, n_inputs)))\n",
    "    y_pred2 = sess.run(outputs, feed_dict={X: X_new})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 576x411.429 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(figsize=(8, 8/1.4))\n",
    "plt.title(\"Testing the model\", fontsize=14)\n",
    "plt.plot(t_instance[:-1], time_series(t_instance[:-1]),\n",
    "         \"o\", c=colors[0], markersize=8, label=\"instance\")\n",
    "plt.plot(t_instance[1:], time_series(t_instance[1:]),\n",
    "         \"^\", c=colors[3], markersize=6, label=\"target\")\n",
    "plt.plot(t_instance[1:], y_pred2[0,:,0],\n",
    "         \".\", c=colors[2], markersize=8, label=\"3-RNN\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel(\"Time\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Compare single RNN and multiple RNN\", fontsize=14)\n",
    "plt.plot(t_instance[1:], time_series(t_instance[1:]),\n",
    "         \".\", c=colors[1], markersize=6, label=\"target\")\n",
    "plt.plot(t_instance[1:], y_pred1[0,:,0],\n",
    "         \"^\", c=colors[0], markersize=5, label=\"single RNN\")\n",
    "plt.plot(t_instance[1:], y_pred2[0,:,0],\n",
    "         \"o\", c=colors[3], markersize=5, label=\"three RNNs\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel(\"Time\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Using a single RNN or three RNNs makes not much difference here, both models did not work well at the beginning of the sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# LSTM\n",
    "## Keys to note in LSTM\n",
    "\n",
    "LSTM has three gates to control the flow of information from the past state: 1) a gate to forget; 2) a gate to include; 3) and the output gate. The gates are implemented with a sigmoid function. \n",
    "\n",
    "Equations in LSTM\n",
    "- Include (remember) gate: $i_{(t)} = \\sigma(W_{xi}^T\\cdot x_{(t)} + W_{hi}^T\\cdot h_{(t-1)}) + b_i$\n",
    "- Forget gate: $f_{(t)} = \\sigma(W_{xf}^T\\cdot x_{(t)} + W_{hf}^T\\cdot h_{(t-1)}) + b_f$\n",
    "- Output gate: $o_{(t)} = \\sigma(W_{xo}^T\\cdot x_{(t)} + W_{hg}^T\\cdot h_{(t-1)} + b_o$\n",
    "- $g_{(t)} = \\tanh(W_{xg})^T\\cdot x_{(t)} + W_{hg}^T\\cdot h_{(t-1)} + b_g$\n",
    "- $c_{(t)} = f_{(t)} \\otimes c_{(t-1)} + i_{(t)}\\otimes g_{(t)}$\n",
    "- $y_{(t)}=h_{(t)}=o_{(t)}\\otimes \\tanh(c_{(t)})$\n",
    "\n",
    " ![lstm](./LSTM3-chain.png)\n",
    " > Figure obtained from [colah](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)                                \n",
    "                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "name": "rnn-nlp.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
